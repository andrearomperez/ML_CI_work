# Report 4 - Statistical Challenges in Online Controlled Experiments: A Review of A/B Testing Methodology
Online Controlled Experiments (OCEs) have become crucial for businesses in the digital world, helping them make more money and improve user experiences. These experiments give organizations a way to test changes or interventions on digital platforms in a structured manner. This allows them to use real evidence to decide if the changes will work before making them public.


The paper "Statistical Challenges in Online Controlled Experiments: A Review of A/B Testing Methodology" aims to provide insights into effective methodologies and practices for online experimentation, regarding sensitivity, effect size, heterogeneity, long-term effects, optional stopping, and interference.


As with any investigation, the article has several strengths and limitations. On one hand, the document is considered extremely relevant since it emphasizes the importance of collaboration between industry and academia. In fact, it highlights real-world applications like Google’s famous “41 shades of blue”, a classic example of an OCE that resulted in a $200 million (USD) increase in annual revenue, according to the authors. This underscores the need for academic statisticians to be aware of research opportunities in online experimentation. Additionally, it employs a range of statistical models and methodologies related to online controlled experiments such as Treatment Effects Estimation (traditional RCTs), Heterogeneous Treatment Effects, Exposure Models, Network Exposure Models, and Cluster-Based Randomization. However, one of the main weaknesses of the article is that in attempting to present the statistical limitations encountered in large-scale experiments,, potentially leading to confusion for the reader.


It is important to acknowledge that this paper marks one of the first attempts to provide a thorough review of the statistical literature concerning Online Controlled Experiments (OCEs). In doing so, it plays a significant role in narrowing the knowledge gap between academia and industry on this subject.


Furthermore, an important next step in advancing our understanding of effective methodologies for online experimentation could involve conducting empirical studies or case studies that apply the methodologies discussed in real-world online experimentation settings. This could be accomplished through direct collaboration with a firm to gain access to their data.
